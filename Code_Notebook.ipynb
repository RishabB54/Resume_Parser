{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a2153a",
   "metadata": {},
   "source": [
    "## LOADING AND PREPROCESSING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fa301cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "# function to convert the raw json format into a more clean and acceptable format\n",
    "def json_to_spacy(json_path):\n",
    "    \n",
    "    file = open(json_path, 'r',encoding='utf8')                       # reading JSON file\n",
    "    lines = file.readlines()\n",
    "    training_data = []  \n",
    "    for line in lines:\n",
    "        data = json.loads(line)                                       # converting JSON string into a dictionary\n",
    "        text = data['content'].replace(\"\\n\", \" \")                     # replacing '\\n' with ' '\n",
    "        entities = []\n",
    "        data_annotations = data['annotation']\n",
    "        \n",
    "        if data_annotations is not None:\n",
    "            for annotation in data_annotations:\n",
    "                point = annotation['points'][0]\n",
    "                labels = annotation['label']\n",
    "                \n",
    "                if not isinstance(labels, list):                     # converting labels to list if it is not a list\n",
    "                    labels = [labels]\n",
    "                    \n",
    "                for lname in labels:\n",
    "                    start = point['start']\n",
    "                    end = point['end']\n",
    "                    text = point['text']\n",
    "\n",
    "                    left_diff = len(text) - len(text.lstrip())        \n",
    "                    right_diff = len(text) - len(text.rstrip())\n",
    "                    if left_diff != 0:                              # updating the start and end points based on strip diff.\n",
    "                        start = start + left_diff\n",
    "                    if right_diff != 0:\n",
    "                        end = end - right_diff\n",
    "                    entities.append((start, end + 1 , lname))\n",
    "                    \n",
    "        training_data.append((text, {\"entities\" : entities}))\n",
    "        \n",
    "    return training_data\n",
    "\n",
    "\n",
    "# function to remove leading and trailing whitespaces from entity spans\n",
    "def trim_space(data: list) -> list:\n",
    "\n",
    "    invalid_token = re.compile(r'\\s')             # setting whitespce as invalid token using regular expression\n",
    "\n",
    "    cleaned_data = []                             # array for storing final cleaned data\n",
    "    for text, annotations in data:\n",
    "        entities = annotations['entities']\n",
    "        valid_entities = []\n",
    "        \n",
    "        for start, end, label in entities:\n",
    "            valid_start = start\n",
    "            valid_end = end\n",
    "            \n",
    "            #checking for invalid token in the start of entity\n",
    "            while valid_start < len(text) and invalid_token.match(text[valid_start]):\n",
    "                valid_start += 1\n",
    "                \n",
    "            #checking for invalid token at the end of entity  \n",
    "            while len(text) > valid_end > 1 and invalid_token.match(text[valid_end - 1]):              \n",
    "                valid_end -= 1\n",
    "            valid_entities.append([valid_start, valid_end, label])\n",
    "            \n",
    "        cleaned_data.append((text,valid_entities))\n",
    "    return cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36d74182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Govardhana K',\n",
       " [[1749, 1755, 'Companies worked at'],\n",
       "  [1696, 1702, 'Companies worked at'],\n",
       "  [1417, 1423, 'Companies worked at'],\n",
       "  [1356, 1793, 'Skills'],\n",
       "  [1209, 1215, 'Companies worked at'],\n",
       "  [1136, 1247, 'Skills'],\n",
       "  [928, 932, 'Graduation Year'],\n",
       "  [858, 889, 'College Name'],\n",
       "  [821, 856, 'Degree'],\n",
       "  [787, 791, 'Graduation Year'],\n",
       "  [744, 750, 'Companies worked at'],\n",
       "  [722, 742, 'Designation'],\n",
       "  [658, 664, 'Companies worked at'],\n",
       "  [640, 656, 'Designation'],\n",
       "  [574, 580, 'Companies worked at'],\n",
       "  [555, 572, 'Designation'],\n",
       "  [470, 493, 'Companies worked at'],\n",
       "  [444, 468, 'Designation'],\n",
       "  [308, 314, 'Companies worked at'],\n",
       "  [234, 240, 'Companies worked at'],\n",
       "  [175, 198, 'Companies worked at'],\n",
       "  [93, 136, 'Email Address'],\n",
       "  [39, 48, 'Location'],\n",
       "  [13, 37, 'Designation'],\n",
       "  [0, 12, 'Name']])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = trim_space(json_to_spacy(\"Entity Recognition in Resumes.json\"))\n",
    "data[20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a186f83",
   "metadata": {},
   "source": [
    "##  CREATING A SPACY OBJECT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee3e410",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.tokens import DocBin\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_spacy_doc(data):\n",
    "    nlp = spacy.blank(\"en\") # load a new spacy model\n",
    "    db = DocBin() # create a DocBin object\n",
    "\n",
    "    for text, annot in tqdm(data): # data in previous format\n",
    "        doc = nlp(text) # create doc object from text\n",
    "        ents=[]\n",
    "        entity_indices=[]\n",
    "        for start, end, label in annot :\n",
    "            # add character indexes\n",
    "            skip_entity=False\n",
    "            for idx in range(start,end):\n",
    "                if idx in entity_indices:\n",
    "                    skip_entity=True\n",
    "                    break\n",
    "            if skip_entity==True:\n",
    "                continue\n",
    "            entity_indices=entity_indices+list(range(start,end))\n",
    "            \n",
    "            try:\n",
    "                span = doc.char_span(start, end, label=label)\n",
    "            except:\n",
    "                continue\n",
    "            if span is None:\n",
    "                continue\n",
    "            else:\n",
    "                ents.append(span)\n",
    "            \n",
    "        try:\n",
    "            doc.ents=ents\n",
    "            db.add(doc)\n",
    "        except:\n",
    "            pass\n",
    "    return db\n",
    "\n",
    "db=get_spacy_doc(data)\n",
    "db.to_disk(\"./train.spacy\") # save the docbin object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6745e1b8",
   "metadata": {},
   "source": [
    "## TRAINING AND LOADING THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc925ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy init fill-config base_config.cfg config.cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98afd0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1a674f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!python -m spacy train config.cfg --output ./output --paths.train ./train.spacy --paths.dev ./train.spacy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "396d168d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load(\"output/model-best/\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796aca58",
   "metadata": {},
   "source": [
    "## TESTING THE MODEL ON TRAINING DATA AND PARSING RESUMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f245e484",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,_ in data:\n",
    "    doc = nlp(i)\n",
    "    print([(ent.text, ent.label_) for ent in doc.ents])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d68f3948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting text from pdf\n",
    "from pdfminer.high_level import extract_text\n",
    "def text_from_pdf(pdf):\n",
    "    return extract_text(pdf)\n",
    "\n",
    "# Taking resume as input\n",
    "resume = text_from_pdf(\"Pulkit_Saxena_resume.pdf\")\n",
    "\n",
    "\n",
    "# Removing the punctuations\n",
    "punctuations = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~â€¢'''\n",
    "for i in resume:\n",
    "    if i in punctuations:\n",
    "        resume = resume.replace(i, \"\")\n",
    "        \n",
    "# Obtaing cleaned text from pdf\n",
    "final_text = str.join(\" \", resume.splitlines())\n",
    "\n",
    "from spacy import displacy\n",
    "doc = nlp(final_text)\n",
    "ans = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "displacy.render(doc,style='ent')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba82ce76",
   "metadata": {},
   "source": [
    "## MATCHING  --  GIVING SCORES TO RESUMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "394e0e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_list = open(\"Companies.txt\",\"r\")\n",
    "company_string = company_list.readlines()[0]\n",
    "degree_list=open(\"Degrees.txt\",\"r\")\n",
    "degree_string=degree_list.readlines()[0]\n",
    "skill_list=open(\"Skills.txt\",\"r\")\n",
    "skill_string=skill_list.readlines()[0]\n",
    "skill_string=skill_string.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6635f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "pref_skillS = 30\n",
    "pref_degreeS = 10\n",
    "pref_companiesS = 20\n",
    "\n",
    "matched_skill=0\n",
    "matched_degree=0\n",
    "matched_companies=0\n",
    "for i in ans:\n",
    "    if i[1]=='Companies worked at':\n",
    "        if i[0] in company_string:\n",
    "            matched_companies+=1\n",
    "    if i[1]=='Degree':\n",
    "        if i[0] in degree_string:\n",
    "            matched_degree+=1\n",
    "    if i[1]=='Skills':\n",
    "        if i[0].lower() in skill_string:\n",
    "            matched_skill+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6810637f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The input resume matches 53.45 percent with the required job position.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "similarity=cosine_similarity([[matched_skill,matched_degree,matched_companies]],[[pref_skillS,pref_degreeS,pref_companiesS]])\n",
    "print(f\"The input resume matches {similarity[0][0]*100:.2f} percent with the required job position.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b7f5221",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
